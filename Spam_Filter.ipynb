{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a spam filter with Naive Bayes algorithm.\n",
    "\n",
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our goal is to write a program that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll use a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by *Tiago A. Almeida and José María Gómez Hidalgo*, and it can be downloaded from the The [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "This project is based on and extends a similar project shared by [DataQuest](https://github.com/dataquestio/solutions/blob/master/Mission433Solutions.ipynb).\n",
    "\n",
    "We will use **pandas** to manipluate the data and **re** for working with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "First we read in the dataset and do basic checks - size, head, tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "     Label                                                SMS\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will ü b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n"
     ]
    }
   ],
   "source": [
    "sms_data = pd.read_csv('data/SMSSpamCollection', sep='\\t', header=None, names = ['Label', 'SMS'])\n",
    "print(sms_data.shape)\n",
    "print( sms_data.head() )\n",
    "print( sms_data.tail() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the head/tail we see that most messages are labelled as ham, some are spam. This is normal. Let's check the exact percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that 86.6% messages are ham, and 13.4% are spam. This sample looks representative based on common experience.\n",
    "\n",
    "# Working with the data\n",
    "## Training/Test split\n",
    "Now we split the data into training and test sets (the usual 80/20 split). 80% for the training and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is  (4458, 2)  and the shape of test data is  (1114, 2)\n",
      "Training set: \n",
      " Label\n",
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: proportion, dtype: float64\n",
      "Test set: \n",
      " Label\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First randomise the dataset\n",
    "data_randomised = sms_data.sample(frac = 1, random_state= 1)\n",
    "\n",
    "# Calculate index for split at 80% of data\n",
    "split_index = round(len(data_randomised) * 0.8 )\n",
    "\n",
    "# Training/ test split at the split_index\n",
    "training_data = data_randomised[ : split_index ].reset_index(drop=True)\n",
    "test_data = data_randomised[ split_index: ].reset_index(drop=True)\n",
    "\n",
    "print(\"Shape of training data is \", training_data.shape, \" and the shape of test data is \", test_data.shape)\n",
    "\n",
    "# Now do a sanity check to see that both sets of data has the ham/spam ratio of the original data.\n",
    "print (\"Training set: \\n\", training_data['Label'].value_counts(normalize=True) )\n",
    "print (\"Test set: \\n\", test_data['Label'].value_counts(normalize=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios look similar to the original dataset, which his good. We now move on to clean the dataset.\n",
    "\n",
    "## Data cleaning\n",
    "In order to work with the algorithm for calculating probabilities, we need to convert all the text messages to see the number of keywords. The below image captures the essence of what we need to do.\n",
    "\n",
    "![](data_cleaning.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove punctuation and convert everything to lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data before cleaning: \n",
      "   Label                                                SMS\n",
      "0   ham                       Yep, by the pretty sculpture\n",
      "1   ham      Yes, princess. Are you going to make me moan?\n",
      "2   ham                         Welp apparently he retired\n",
      "3   ham                                            Havent.\n",
      "4   ham  I forgot 2 ask ü all smth.. There's a card on ...\n",
      "Data after cleaning: \n",
      "   Label                                                SMS\n",
      "0   ham                       yep  by the pretty sculpture\n",
      "1   ham      yes  princess  are you going to make me moan \n",
      "2   ham                         welp apparently he retired\n",
      "3   ham                                            havent \n",
      "4   ham  i forgot 2 ask ü all smth   there s a card on ...\n"
     ]
    }
   ],
   "source": [
    "# Remove all the punctuation and bring all letters to lower case\n",
    "print(\"Data before cleaning: \\n\", training_data.head())\n",
    "\n",
    "training_data['SMS'] = training_data['SMS'].str.replace(r'\\W', ' ', regex=True) # replace any non-word characters with a space\n",
    "training_data['SMS'] = training_data['SMS'].str.lower() # convert everything to lower case\n",
    "\n",
    "print(\"Data after cleaning: \\n\", training_data.head())\n",
    "\n",
    "# print(training_data['SMS'].str.replace(r'\\W', ' ', regex=True).head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a vocabulary of all the unique words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of words in our vocabulary is  7783\n"
     ]
    }
   ],
   "source": [
    "training_data['SMS'] = training_data['SMS'].str.split() # this converts SMS column into a list of all the words\n",
    "\n",
    "vocabulary = []\n",
    "\n",
    "for sms in training_data['SMS']:\n",
    "    for word in sms:\n",
    "        vocabulary.append(word)\n",
    "\n",
    "# Currently vocabulary contains all the words in the dataset. Remove duplicates:\n",
    "vocabulary = set(vocabulary)\n",
    "print(\"The total number of words in our vocabulary is\", len(vocabulary))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>babygoodbye</th>\n",
       "      <th>checkup</th>\n",
       "      <th>hi</th>\n",
       "      <th>86688</th>\n",
       "      <th>izzit</th>\n",
       "      <th>install</th>\n",
       "      <th>anythingtomorrow</th>\n",
       "      <th>year</th>\n",
       "      <th>great</th>\n",
       "      <th>days</th>\n",
       "      <th>...</th>\n",
       "      <th>activities</th>\n",
       "      <th>dartboard</th>\n",
       "      <th>when</th>\n",
       "      <th>gd</th>\n",
       "      <th>understanding</th>\n",
       "      <th>tool</th>\n",
       "      <th>thangam</th>\n",
       "      <th>100p</th>\n",
       "      <th>swell</th>\n",
       "      <th>09061790121</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7783 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   babygoodbye  checkup  hi  86688  izzit  install  anythingtomorrow  year  \\\n",
       "0            0        0   0      0      0        0                 0     0   \n",
       "1            0        0   0      0      0        0                 0     0   \n",
       "2            0        0   0      0      0        0                 0     0   \n",
       "3            0        0   0      0      0        0                 0     0   \n",
       "4            0        0   0      0      0        0                 0     0   \n",
       "\n",
       "   great  days  ...  activities  dartboard  when  gd  understanding  tool  \\\n",
       "0      0     0  ...           0          0     0   0              0     0   \n",
       "1      0     0  ...           0          0     0   0              0     0   \n",
       "2      0     0  ...           0          0     0   0              0     0   \n",
       "3      0     0  ...           0          0     0   0              0     0   \n",
       "4      0     0  ...           0          0     0   0              0     0   \n",
       "\n",
       "   thangam  100p  swell  09061790121  \n",
       "0        0     0      0            0  \n",
       "1        0     0      0            0  \n",
       "2        0     0      0            0  \n",
       "3        0     0      0            0  \n",
       "4        0     0      0            0  \n",
       "\n",
       "[5 rows x 7783 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First initialise a dictionary with zeros. Each word corresponds to a list of numbers of how many times it appears in each sms.\n",
    "word_count_per_sms = {unique_word: [0]* len(training_data['SMS']) for unique_word in vocabulary }\n",
    "\n",
    "# This loop assigns the current frequency of each word.\n",
    "for index, sms in enumerate(training_data['SMS']):\n",
    "    for word in sms:\n",
    "        word_count_per_sms[word][index] +=1 \n",
    "\n",
    "# Now convert this dictionary to a dataframe\n",
    "word_counts = pd.DataFrame(word_count_per_sms)\n",
    "word_counts.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Label</th>\n",
       "      <th>SMS</th>\n",
       "      <th>babygoodbye</th>\n",
       "      <th>checkup</th>\n",
       "      <th>hi</th>\n",
       "      <th>86688</th>\n",
       "      <th>izzit</th>\n",
       "      <th>install</th>\n",
       "      <th>anythingtomorrow</th>\n",
       "      <th>year</th>\n",
       "      <th>...</th>\n",
       "      <th>activities</th>\n",
       "      <th>dartboard</th>\n",
       "      <th>when</th>\n",
       "      <th>gd</th>\n",
       "      <th>understanding</th>\n",
       "      <th>tool</th>\n",
       "      <th>thangam</th>\n",
       "      <th>100p</th>\n",
       "      <th>swell</th>\n",
       "      <th>09061790121</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yep, by, the, pretty, sculpture]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>[yes, princess, are, you, going, to, make, me,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ham</td>\n",
       "      <td>[welp, apparently, he, retired]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>[havent]</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>[i, forgot, 2, ask, ü, all, smth, there, s, a,...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 7785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Label                                                SMS  babygoodbye  \\\n",
       "0   ham                  [yep, by, the, pretty, sculpture]            0   \n",
       "1   ham  [yes, princess, are, you, going, to, make, me,...            0   \n",
       "2   ham                    [welp, apparently, he, retired]            0   \n",
       "3   ham                                           [havent]            0   \n",
       "4   ham  [i, forgot, 2, ask, ü, all, smth, there, s, a,...            0   \n",
       "\n",
       "   checkup  hi  86688  izzit  install  anythingtomorrow  year  ...  \\\n",
       "0        0   0      0      0        0                 0     0  ...   \n",
       "1        0   0      0      0        0                 0     0  ...   \n",
       "2        0   0      0      0        0                 0     0  ...   \n",
       "3        0   0      0      0        0                 0     0  ...   \n",
       "4        0   0      0      0        0                 0     0  ...   \n",
       "\n",
       "   activities  dartboard  when  gd  understanding  tool  thangam  100p  swell  \\\n",
       "0           0          0     0   0              0     0        0     0      0   \n",
       "1           0          0     0   0              0     0        0     0      0   \n",
       "2           0          0     0   0              0     0        0     0      0   \n",
       "3           0          0     0   0              0     0        0     0      0   \n",
       "4           0          0     0   0              0     0        0     0      0   \n",
       "\n",
       "   09061790121  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 7785 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now merge the above with the modified training set dataframe to get the final dataset to work with\n",
    "training_data_clean = pd.concat([training_data, word_counts], axis= 1)\n",
    "training_data_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
