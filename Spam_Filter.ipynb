{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building a spam filter with Naive Bayes algorithm.\n",
    "\n",
    "In this project, we're going to build a spam filter for SMS messages using the multinomial Naive Bayes algorithm. Our goal is to write a program that classifies new messages with an accuracy greater than 80% — so we expect that more than 80% of the new messages will be classified correctly as spam or ham (non-spam).\n",
    "\n",
    "To train the algorithm, we'll use a dataset of 5,572 SMS messages that are already classified by humans. The dataset was put together by *Tiago A. Almeida and José María Gómez Hidalgo*, and it can be downloaded from the The [UCI Machine Learning Repository](https://archive.ics.uci.edu/dataset/228/sms+spam+collection).\n",
    "\n",
    "This project is based on and extends a similar project shared by [DataQuest](https://github.com/dataquestio/solutions/blob/master/Mission433Solutions.ipynb).\n",
    "\n",
    "We will use **pandas** to manipluate the data and **re** for working with text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the Dataset\n",
    "\n",
    "First we read in the dataset and do basic checks - size, head, tail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 2)\n",
      "  Label                                                SMS\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "     Label                                                SMS\n",
      "5567  spam  This is the 2nd time we have tried 2 contact u...\n",
      "5568   ham               Will ü b going to esplanade fr home?\n",
      "5569   ham  Pity, * was in mood for that. So...any other s...\n",
      "5570   ham  The guy did some bitching but I acted like i'd...\n",
      "5571   ham                         Rofl. Its true to its name\n"
     ]
    }
   ],
   "source": [
    "sms_data = pd.read_csv('data/SMSSpamCollection', sep='\\t', header=None, names = ['Label', 'SMS'])\n",
    "print(sms_data.shape)\n",
    "print( sms_data.head() )\n",
    "print( sms_data.tail() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the head/tail we see that most messages are labelled as ham, some are spam. This is normal. Let's check the exact percentages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "ham     0.865937\n",
       "spam    0.134063\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sms_data['Label'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see above that 86.6% messages are ham, and 13.4% are spam. This sample looks representative based on common experience.\n",
    "\n",
    "# Working with the data\n",
    "## Training/Test split\n",
    "Now we split the data into training and test sets (the usual 80/20 split). 80% for the training and 20% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training data is  (4458, 2)  and the shape of test data is  (1114, 2)\n",
      "Training set: \n",
      " Label\n",
      "ham     0.86541\n",
      "spam    0.13459\n",
      "Name: proportion, dtype: float64\n",
      "Test set: \n",
      " Label\n",
      "ham     0.868043\n",
      "spam    0.131957\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# First randomise the dataset\n",
    "data_randomised = sms_data.sample(frac = 1, random_state= 1)\n",
    "\n",
    "# Calculate index for split at 80% of data\n",
    "split_index = round(len(data_randomised) * 0.8 )\n",
    "\n",
    "# Training/ test split at the split_index\n",
    "training_data = data_randomised[ : split_index ].reset_index(drop=True)\n",
    "test_data = data_randomised[ split_index: ].reset_index(drop=True)\n",
    "\n",
    "print(\"Shape of training data is \", training_data.shape, \" and the shape of test data is \", test_data.shape)\n",
    "\n",
    "# Now do a sanity check to see that both sets of data has the ham/spam ratio of the original data.\n",
    "print (\"Training set: \\n\", training_data['Label'].value_counts(normalize=True) )\n",
    "print (\"Test set: \\n\", test_data['Label'].value_counts(normalize=True) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios look similar to the original dataset, which his good. We now move on to clean the dataset.\n",
    "\n",
    "## Data cleaning\n",
    "In order to work with the algorithm for calculating probabilities, we need to convert all the text messages to see the number of keywords. The below imae captures the essence of what we need to do.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
